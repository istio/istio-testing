/*
Copyright 2019 Istio Authors

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
*/

package genjobs

import (
	"errors"
	"fmt"
	"io/ioutil"
	"os"
	"path/filepath"
	"regexp"
	"sort"
	"strings"

	flag "github.com/spf13/pflag"
	v1 "k8s.io/api/core/v1"
	"k8s.io/apimachinery/pkg/util/sets"
	prowjob "k8s.io/test-infra/prow/apis/prowjobs/v1"
	"k8s.io/test-infra/prow/config"
	"sigs.k8s.io/yaml"

	"istio.io/test-infra/prow/genjobs/pkg/util"
)

const (
	autogenHeader     = "# THIS FILE IS AUTOGENERATED. DO NOT EDIT. See genjobs/README.md\n"
	filenameSeparator = "."
	jobnameSeparator  = "_"
	gitHost           = "github.com"
	maxLabelLen       = 63
	defaultModifier   = "private"
	defaultCluster    = "default"
	yamlExt           = ".(yml|yaml)$"
)

var (
	defaultJobTypes = []string{"presubmit", "postsubmit", "periodic"}
)

// sortOrder is the type to define sort order.
type sortOrder string

const (
	ascending  sortOrder = "asc"
	descending sortOrder = "desc"
)

// configuration is the yaml configuration file format.
type configuration struct {
	Transforms []transform `json:"transforms,omitempty"`
}

// transform are the available transformation fields.
type transform struct {
	Annotations      map[string]string `json:"annotations,omitempty"`
	Bucket           string            `json:"bucket,omitempty"`
	Cluster          string            `json:"cluster,omitempty"`
	Channel          string            `json:"channel,omitempty"`
	SSHKeySecret     string            `json:"ssh-key-secret,omitempty"`
	Modifier         string            `json:"modifier,omitempty"`
	Input            string            `json:"input,omitempty"`
	Output           string            `json:"output,omitempty"`
	Sort             string            `json:"sort,omitempty"`
	Branches         []string          `json:"branches,omitempty"`
	BranchesOut      []string          `json:"branches-out,omitempty"`
	Presets          []string          `json:"presets,omitempty"`
	RerunOrgs        []string          `json:"rerun-orgs,omitempty"`
	RerunUsers       []string          `json:"rerun-users,omitempty"`
	JobWhitelist     []string          `json:"job-whitelist,omitempty"`
	JobBlacklist     []string          `json:"job-blacklist,omitempty"`
	RepoWhitelist    []string          `json:"repo-whitelist,omitempty"`
	RepoBlacklist    []string          `json:"repo-blacklist,omitempty"`
	JobType          []string          `json:"job-type,omitempty"`
	Selector         map[string]string `json:"selector,omitempty"`
	Labels           map[string]string `json:"labels,omitempty"`
	Env              map[string]string `json:"env,omitempty"`
	OrgMap           map[string]string `json:"mapping,omitempty"`
	Clean            bool              `json:"clean,omitempty"`
	DryRun           bool              `json:"dry-run,omitempty"`
	ExtraRefs        bool              `json:"extra-refs,omitempty"`
	Resolve          bool              `json:"resolve,omitempty"`
	SSHClone         bool              `json:"ssh-clone,omitempty"`
	OverrideSelector bool              `json:"override-selector,omitempty"`
	Verbose          bool              `json:"verbose,omitempty"`
}

// options are the available command-line flags.
type options struct {
	Configs          []string
	JobWhitelistSet  sets.String
	JobBlacklistSet  sets.String
	RepoWhitelistSet sets.String
	RepoBlacklistSet sets.String
	JobTypeSet       sets.String
	transform
}

// parseOpts parses the command-line flags.
func (o *options) parseOpts() {
	flag.StringVar(&o.Bucket, "bucket", "", "GCS bucket name to upload logs and build artifacts to.")
	flag.StringVar(&o.Cluster, "cluster", "", "GCP cluster to run the job(s) in.")
	flag.StringVar(&o.Channel, "channel", "", "Slack channel to report job status notifications to.")
	flag.StringVar(&o.SSHKeySecret, "ssh-key-secret", "", "GKE cluster secrets containing the Github ssh private key.")
	flag.StringVar(&o.Modifier, "modifier", defaultModifier, "Modifier to apply to generated file and job name(s).")
	flag.StringVarP(&o.Input, "input", "i", ".", "Input file or directory containing job(s) to convert.")
	flag.StringVarP(&o.Output, "output", "o", ".", "Output file or directory to write generated job(s).")
	flag.StringVarP(&o.Sort, "sort", "s", "", "Sort the job(s) by name: (e.g. (asc)ending, (desc)ending).")
	flag.StringSliceVar(&o.Branches, "branches", []string{}, "Branch(es) to generate job(s) for.")
	flag.StringSliceVar(&o.BranchesOut, "branches-out", []string{}, "Override output branch(es) for generated job(s).")
	flag.StringSliceVar(&o.Configs, "configs", []string{}, "Path to files or directories containing yaml job transforms.")
	flag.StringSliceVarP(&o.Presets, "presets", "p", []string{}, "Path to file(s) containing additional presets.")
	flag.StringSliceVar(&o.RerunOrgs, "rerun-orgs", []string{}, "GitHub organizations to authorize job rerun for.")
	flag.StringSliceVar(&o.RerunUsers, "rerun-users", []string{}, "GitHub user to authorize job rerun for.")
	flag.StringToStringVar(&o.Selector, "selector", map[string]string{}, "Node selector(s) to constrain job(s).")
	flag.StringToStringVarP(&o.Labels, "labels", "l", map[string]string{}, "Prow labels to apply to the job(s).")
	flag.StringToStringVarP(&o.Env, "env", "e", map[string]string{}, "Environment variables to set for the job(s).")
	flag.StringToStringVarP(&o.OrgMap, "mapping", "m", map[string]string{}, "Mapping between public and private Github organization(s).")
	flag.StringToStringVarP(&o.Annotations, "annotations", "a", map[string]string{}, "Annotations to apply to the job(s)")
	flag.StringSliceVar(&o.JobWhitelist, "job-whitelist", []string{}, "Job(s) to whitelist in generation process.")
	flag.StringSliceVar(&o.JobBlacklist, "job-blacklist", []string{}, "Job(s) to blacklist in generation process.")
	flag.StringSliceVarP(&o.RepoWhitelist, "repo-whitelist", "w", []string{}, "Repositories to whitelist in generation process.")
	flag.StringSliceVarP(&o.RepoBlacklist, "repo-blacklist", "b", []string{}, "Repositories to blacklist in generation process.")
	flag.StringSliceVarP(&o.JobType, "job-type", "t", defaultJobTypes, "Job type(s) to process (e.g. presubmit, postsubmit. periodic).")
	flag.BoolVar(&o.Clean, "clean", false, "Clean output files before job(s) generation.")
	flag.BoolVar(&o.DryRun, "dry-run", false, "Run in dry run mode.")
	flag.BoolVar(&o.ExtraRefs, "extra-refs", false, "Apply translation to all extra refs regardless of repo.")
	flag.BoolVar(&o.Resolve, "resolve", false, "Resolve and expand values for presets in generated job(s).")
	flag.BoolVar(&o.SSHClone, "ssh-clone", false, "Enable a clone of the git repository over ssh.")
	flag.BoolVar(&o.OverrideSelector, "override-selector", false, "The existing node selector will be overridden rather than added to.")
	flag.BoolVar(&o.Verbose, "verbose", false, "Enable verbose output.")

	flag.Parse()

	o.JobWhitelistSet = sets.NewString(o.JobWhitelist...)
	o.JobBlacklistSet = sets.NewString(o.JobBlacklist...)
	o.RepoWhitelistSet = sets.NewString(o.RepoWhitelist...)
	o.RepoBlacklistSet = sets.NewString(o.RepoBlacklist...)
	o.JobTypeSet = sets.NewString(o.JobType...)
}

// parseConfiguration parses the yaml configuration transforms.
func (o *options) parseConfiguration() []options {
	var optsList []options

	for _, c := range o.Configs {

		if err := filepath.Walk(c, func(path string, info os.FileInfo, err error) error {
			if err != nil {
				return nil
			}

			if !util.HasExtension(path, yamlExt) {
				return nil
			}

			f, err := ioutil.ReadFile(path)
			if err != nil {
				return nil
			}

			var t configuration
			if err := yaml.Unmarshal(f, &t); err != nil {
				return nil
			}

			for _, t := range t.Transforms {
				if len(t.JobType) == 0 {
					t.JobType = defaultJobTypes
				}

				oc := options{
					JobWhitelistSet:  sets.NewString(t.JobWhitelist...),
					JobBlacklistSet:  sets.NewString(t.JobBlacklist...),
					RepoWhitelistSet: sets.NewString(t.RepoWhitelist...),
					RepoBlacklistSet: sets.NewString(t.RepoBlacklist...),
					JobTypeSet:       sets.NewString(t.JobType...),
					transform:        t,
				}

				if err := oc.validateOpts(); err != nil {
					util.PrintErrAndExit(err)
				}

				optsList = append(optsList, oc)
			}

			return nil
		}); err != nil {
			util.PrintErr(err.Error())
		}
	}

	return optsList
}

// validateOpts validates the command-line flags.
func (o *options) validateOpts() error {
	var err error

	for i, c := range o.Configs {
		if o.Configs[i], err = filepath.Abs(c); err != nil {
			return &util.ExitError{Message: fmt.Sprintf("--configs option invalid: %v.", o.Configs[i]), Code: 1}
		} else if !util.Exists(o.Configs[i]) {
			return &util.ExitError{Message: fmt.Sprintf("--configs option path does not exists: %v.", o.Configs[i]), Code: 1}
		} else if util.IsFile(o.Configs[i]) && !util.HasExtension(o.Configs[i], yamlExt) {
			return &util.ExitError{Message: fmt.Sprintf("--configs option path is not a yaml file: %v.", o.Configs[i]), Code: 1}
		}
	}

	if len(o.Configs) == 0 {
		if len(o.OrgMap) == 0 {
			return &util.ExitError{Message: "-m, --mapping option is required.", Code: 1}
		}

		if o.Input, err = filepath.Abs(o.Input); err != nil {
			return &util.ExitError{Message: fmt.Sprintf("-i, --input option invalid: %v.", o.Input), Code: 1}
		}

		if o.Output, err = filepath.Abs(o.Output); err != nil {
			return &util.ExitError{Message: fmt.Sprintf("-o, --output option invalid: %v.", o.Output), Code: 1}
		}

		for i, c := range o.Presets {
			if o.Presets[i], err = filepath.Abs(c); err != nil {
				return &util.ExitError{Message: fmt.Sprintf("-p, --preset option invalid: %v.", o.Presets[i]), Code: 1}
			} else if !util.Exists(o.Presets[i]) {
				return &util.ExitError{Message: fmt.Sprintf("-p, --preset option path does not exists: %v.", o.Presets[i]), Code: 1}
			} else if util.IsFile(o.Presets[i]) && !util.HasExtension(o.Presets[i], yamlExt) {
				return &util.ExitError{Message: fmt.Sprintf("-p, --preset option path is not a yaml file: %v.", o.Presets[i]), Code: 1}
			}
		}
	}

	return nil
}

// validateOrgRepo validates that the org and repo for a job pass validation and should be converted.
func validateOrgRepo(o options, org string, repo string) bool {
	_, hasOrg := o.OrgMap[org]

	if !hasOrg || o.RepoBlacklistSet.Has(repo) || (len(o.RepoWhitelistSet) > 0 && !o.RepoWhitelistSet.Has(repo)) {
		return false
	}

	return true
}

// validateJob validates that the job passes validation and should be converted.
func validateJob(o options, name string, patterns []string, jType string) bool {
	if o.JobBlacklistSet.Has(name) || (len(o.JobWhitelistSet) > 0 && !o.JobWhitelistSet.Has(name)) || !isMatchBranch(o, patterns) || !o.JobTypeSet.Has(jType) {
		return false
	}

	return true
}

// isMatchBranch validates that the branch for a job passes validation and should be converted.
func isMatchBranch(o options, patterns []string) bool {
	if len(o.Branches) == 0 {
		return true
	}

	for _, branch := range o.Branches {
		for _, pattern := range patterns {
			if regexp.MustCompile(pattern).MatchString(branch) {
				return true
			}
		}
	}

	return false
}

// allRefs returns true if all predicate function returns true for the array of ref.
func allRefs(array []prowjob.Refs, predicate func(val prowjob.Refs, idx int) bool) bool {
	for idx, item := range array {
		if !predicate(item, idx) {
			return false
		}
	}
	return true
}

// convertOrgRepoStr translates the provided job org and repo based on the specified org mapping.
func convertOrgRepoStr(o options, s string) string {
	org, repo := util.SplitOrgRepo(s)

	valid := validateOrgRepo(o, org, repo)

	if !valid {
		return ""
	}

	return strings.Join([]string{o.OrgMap[org], repo}, "/")
}

// combinePresets reads a list of paths and aggregates the presets.
func combinePresets(paths []string) []config.Preset {
	presets := []config.Preset{}

	if len(paths) == 0 {
		return presets
	}

	for _, p := range paths {
		c, err := config.ReadJobConfig(p)
		if err != nil {
			continue
		}
		presets = append(presets, c.Presets...)
	}

	return presets
}

// mergePreset merges a preset into a job Spec based on defined labels.
func mergePreset(labels map[string]string, job *config.JobBase, preset config.Preset) {
	for l, v := range preset.Labels {
		if v2, exists := labels[l]; !exists || v != v2 {
			return
		}
	}

	for _, env := range preset.Env {
	econtainer:
		for i := range job.Spec.Containers {
			for j := range job.Spec.Containers[i].Env {
				if job.Spec.Containers[i].Env[j].Name == env.Name {
					job.Spec.Containers[i].Env[j].Value = env.Value
					continue econtainer
				}
			}

			job.Spec.Containers[i].Env = append(job.Spec.Containers[i].Env, env)
		}
	}

volume:
	for _, vol := range preset.Volumes {

		for i := range job.Spec.Volumes {
			if job.Spec.Volumes[i].Name == vol.Name {
				job.Spec.Volumes[i] = vol
				continue volume
			}

		}

		job.Spec.Volumes = append(job.Spec.Volumes, vol)
	}

	for _, volm := range preset.VolumeMounts {
	vcontainer:
		for i := range job.Spec.Containers {
			for j := range job.Spec.Containers[i].VolumeMounts {
				if job.Spec.Containers[i].VolumeMounts[j].Name == volm.Name {
					job.Spec.Containers[i].VolumeMounts[j] = volm
					continue vcontainer
				}
			}

			job.Spec.Containers[i].VolumeMounts = append(job.Spec.Containers[i].VolumeMounts, volm)
		}
	}
}

// resolvePresets resolves all preset for a particular job Spec based on defined labels.
func resolvePresets(o options, labels map[string]string, job *config.JobBase, presets []config.Preset) {
	if !o.Resolve {
		return
	}

	if job.Spec != nil {
		for _, preset := range presets {
			mergePreset(labels, job, preset)
		}
	}
}

// updateJobName updates the jobs Name fields based on provided inputs.
func updateJobName(o options, job *config.JobBase) {
	suffix := ""

	if o.Modifier != "" {
		suffix = jobnameSeparator + o.Modifier
	}

	maxNameLen := maxLabelLen - len(suffix)

	if len(job.Name) > maxNameLen {
		job.Name = job.Name[:maxNameLen]
	}

	job.Name += suffix
}

// updateBrancher updates the jobs Brancher fields based on provided inputs.
func updateBrancher(o options, job *config.Brancher) {
	if len(o.BranchesOut) == 0 {
		return
	}

	job.Branches = o.BranchesOut
}

// updateUtilityConfig updates the jobs UtilityConfig fields based on provided inputs.
func updateUtilityConfig(o options, job *config.UtilityConfig) {
	if o.Bucket == "" && o.SSHKeySecret == "" {
		return
	}

	if job.DecorationConfig == nil {
		job.DecorationConfig = &prowjob.DecorationConfig{}
	}

	updateGCSConfiguration(o, job.DecorationConfig)
	updateSSHKeySecrets(o, job.DecorationConfig)
}

// updateGCSConfiguration updates the jobs GCSConfiguration fields based on provided inputs.
func updateGCSConfiguration(o options, job *prowjob.DecorationConfig) {
	if o.Bucket == "" {
		return
	}

	if job.GCSConfiguration == nil {
		job.GCSConfiguration = &prowjob.GCSConfiguration{
			Bucket: o.Bucket,
		}
	} else {
		job.GCSConfiguration.Bucket = o.Bucket
	}
}

// updateSSHKeySecrets updates the jobs SSHKeySecrets fields based on provided inputs.
func updateSSHKeySecrets(o options, job *prowjob.DecorationConfig) {
	if o.SSHKeySecret == "" {
		return
	}

	if job.SSHKeySecrets == nil {
		job.SSHKeySecrets = []string{o.SSHKeySecret}
	} else {
		job.SSHKeySecrets = append(job.SSHKeySecrets, o.SSHKeySecret)
	}
}

// updateReporterConfig updates the jobs ReporterConfig fields based on provided inputs.
func updateReporterConfig(o options, job *config.JobBase) {
	if o.Channel == "" {
		return
	}

	if job.ReporterConfig == nil {
		job.ReporterConfig = &prowjob.ReporterConfig{}
	}

	job.ReporterConfig.Slack = &prowjob.SlackReporterConfig{Channel: o.Channel}
}

// updateRerunAuthConfig updates the jobs RerunAuthConfig fields based on provided inputs.
func updateRerunAuthConfig(o options, job *config.JobBase) {
	if len(o.RerunOrgs) == 0 && len(o.RerunUsers) == 0 {
		return
	}

	// The original job `RerunAuthConfig` is overwritten with the user-defined values.
	job.RerunAuthConfig = &prowjob.RerunAuthConfig{
		GitHubOrgs:  o.RerunOrgs,
		GitHubUsers: o.RerunUsers,
	}
}

// updateLabels updates the jobs Labels fields based on provided inputs.
func updateLabels(o options, job *config.JobBase) {
	if len(o.Labels) == 0 {
		return
	}

	if job.Labels == nil {
		job.Labels = make(map[string]string)
	}

	for labelK, labelV := range o.Labels {
		job.Labels[labelK] = labelV
	}
}

// updateNodeSelector updates the jobs NodeSelector fields based on provided inputs.
func updateNodeSelector(o options, job *config.JobBase) {
	if o.OverrideSelector {
		job.Spec.NodeSelector = make(map[string]string)
	}

	if len(o.Selector) == 0 {
		return
	}

	if job.Spec.NodeSelector == nil {
		job.Spec.NodeSelector = make(map[string]string)
	}

	for selK, selV := range o.Selector {
		job.Spec.NodeSelector[selK] = selV
	}
}

// updateEnvs updates the jobs Env fields based on provided inputs.
func updateEnvs(o options, job *config.JobBase) {
	if len(o.Env) == 0 {
		return
	}

	envKs := util.SortedKeys(o.Env)

	for _, envK := range envKs {
	container:
		for i := range job.Spec.Containers {

			for j := range job.Spec.Containers[i].Env {
				if job.Spec.Containers[i].Env[j].Name == envK {
					job.Spec.Containers[i].Env[j].Value = o.Env[envK]
					continue container
				}
			}

			job.Spec.Containers[i].Env = append(job.Spec.Containers[i].Env, v1.EnvVar{Name: envK, Value: o.Env[envK]})
		}
	}
}

// updateJobBase updates the jobs JobBase fields based on provided inputs to work with private repositories.
func updateJobBase(o options, job *config.JobBase, orgrepo string) {
	job.Annotations = o.Annotations

	if o.SSHClone && orgrepo != "" {
		job.CloneURI = fmt.Sprintf("git@%s:%s.git", gitHost, orgrepo)
	}

	if o.Cluster != "" && o.Cluster != defaultCluster {
		job.Cluster = o.Cluster
	}

	updateJobName(o, job)
	updateReporterConfig(o, job)
	updateRerunAuthConfig(o, job)
	updateLabels(o, job)
	updateNodeSelector(o, job)
	updateEnvs(o, job)
}

// updateExtraRefs updates the jobs ExtraRefs fields based on provided inputs to work with private repositories.
func updateExtraRefs(o options, refs []prowjob.Refs) {
	for i, ref := range refs {
		org, repo := ref.Org, ref.Repo

		if o.ExtraRefs || validateOrgRepo(o, org, repo) {
			// Only transform known org mappings.
			if newOrg, ok := o.OrgMap[org]; ok {
				org = newOrg
			}
			refs[i].Org = org
			if o.SSHClone {
				refs[i].CloneURI = fmt.Sprintf("git@%s:%s/%s.git", gitHost, org, repo)
			}
		}
	}
}

// sortJobs sorts jobs based on a provided sort order.
func sortJobs(o options, pre map[string][]config.Presubmit, post map[string][]config.Postsubmit, per []config.Periodic) {
	if o.Sort == "" {
		return
	}

	choices := strings.Join([]string{string(ascending), string(descending)}, "|")
	matches := regexp.MustCompile(`^(` + choices + `)(?:ending)?$`).FindStringSubmatch(o.Sort)
	if len(matches) < 2 {
		return
	}

	var comparator func(a, b string) bool

	switch sortOrder(matches[1]) {
	case ascending:
		comparator = func(a, b string) bool {
			return a < b
		}
	case descending:
		comparator = func(a, b string) bool {
			return a > b
		}
	}

	for _, c := range pre {
		sort.Slice(c, func(a, b int) bool {
			return comparator(c[a].Name, c[b].Name)
		})
	}

	for _, c := range post {
		sort.Slice(c, func(a, b int) bool {
			return comparator(c[a].Name, c[b].Name)
		})
	}

	sort.Slice(per, func(a, b int) bool {
		return comparator(per[a].Name, per[b].Name)
	})

}

// getOutPath derives the output path from the specified input directory and current path.
func getOutPath(o options, p string, in string) string {
	segments := strings.FieldsFunc(strings.TrimPrefix(p, in), func(c rune) bool { return c == '/' })

	var (
		org  string
		repo string
		file string
	)

	switch {
	case util.HasExtension(o.Output, yamlExt):
		return o.Output
	case len(segments) >= 3:
		org = segments[len(segments)-3]
		repo = segments[len(segments)-2]
		file = segments[len(segments)-1]
		if newOrg, ok := o.OrgMap[org]; ok {
			filename := util.RenameFile(`^`+util.NormalizeOrg(org, filenameSeparator)+`\b`, file, util.NormalizeOrg(newOrg, filenameSeparator))
			return filepath.Join(o.Output, util.GetTopLevelOrg(newOrg), repo, filename)
		}
	case len(segments) == 2:
		org = segments[len(segments)-2]
		file = segments[len(segments)-1]
		if newOrg, ok := o.OrgMap[org]; ok {
			filename := util.RenameFile(`^`+util.NormalizeOrg(org, filenameSeparator)+`\b`, file, util.NormalizeOrg(newOrg, filenameSeparator))
			return filepath.Join(o.Output, util.GetTopLevelOrg(newOrg), filename)
		}
	case len(segments) == 1:
		file = segments[len(segments)-1]
		if !strings.HasPrefix(file, o.Modifier) {
			return filepath.Join(o.Output, o.Modifier+filenameSeparator+file)
		}
	case len(segments) == 0:
		file = filepath.Base(in)
		if !strings.HasPrefix(file, o.Modifier) {
			return filepath.Join(o.Output, o.Modifier+filenameSeparator+file)
		}
	}

	return ""
}

// cleanOutFile deletes a path and any children.
func cleanOutFile(p string) {
	if err := os.RemoveAll(p); err != nil {
		util.PrintErr(fmt.Sprintf("unable to clean file %v: %v.", p, err))
	}
}

func handleRecover() {
	if r := recover(); r != nil {
		switch t := r.(type) {
		case string:
			util.PrintErrAndExit(errors.New(t))
		case error:
			util.PrintErrAndExit(t)
		default:
			util.PrintErrAndExit(errors.New("unknown panic"))
		}
	}
}

// writeOutFile writes presubmit and postsubmit jobs definitions to the designated output path.
func writeOutFile(o options, p string, pre map[string][]config.Presubmit, post map[string][]config.Postsubmit, per []config.Periodic) {
	if len(pre) == 0 && len(post) == 0 && len(per) == 0 {
		return
	}

	combinedPre := map[string][]config.Presubmit{}
	combinedPost := map[string][]config.Postsubmit{}
	combinedPer := []config.Periodic{}

	existingJobs, err := config.ReadJobConfig(p)
	if err == nil {
		if existingJobs.PresubmitsStatic != nil {
			combinedPre = existingJobs.PresubmitsStatic
		}
		if existingJobs.Postsubmits != nil {
			combinedPost = existingJobs.Postsubmits
		}
		if existingJobs.Periodics != nil {
			combinedPer = existingJobs.Periodics
		}
	}

	// Combine presubmits
	for orgrepo, newPre := range pre {
		if oldPre, exists := combinedPre[orgrepo]; exists {
			combinedPre[orgrepo] = append(oldPre, newPre...)
		} else {
			combinedPre[orgrepo] = newPre
		}
	}

	// Combine postsubmits
	for orgrepo, newPost := range post {
		if oldPost, exists := combinedPost[orgrepo]; exists {
			combinedPost[orgrepo] = append(oldPost, newPost...)
		} else {
			combinedPost[orgrepo] = newPost
		}
	}

	// Combine periodics
	combinedPer = append(combinedPer, per...)

	// Sort presubmits, postsubmits, and periodics
	sortJobs(o, combinedPre, combinedPost, combinedPer)

	jobConfig := config.JobConfig{}

	err = jobConfig.SetPresubmits(combinedPre)
	if err != nil {
		util.PrintErr(fmt.Sprintf("unable to set presubmits for path %v: %v.", p, err))
	}

	err = jobConfig.SetPostsubmits(combinedPost)
	if err != nil {
		util.PrintErr(fmt.Sprintf("unable to set postsubmits for path %v: %v.", p, err))
	}

	jobConfig.Periodics = combinedPer

	jobConfigYaml, err := yaml.Marshal(jobConfig)
	if err != nil {
		util.PrintErr(fmt.Sprintf("unable to marshal job config output directory: %v.", err))
		return
	}

	outBytes := []byte(autogenHeader)
	outBytes = append(outBytes, jobConfigYaml...)

	dir := filepath.Dir(p)

	err = os.MkdirAll(dir, os.ModePerm)
	if err != nil {
		util.PrintErr(fmt.Sprintf("unable to create output directory %v: %v.", dir, err))
	}

	err = ioutil.WriteFile(p, outBytes, 0644)
	if err != nil {
		util.PrintErr(fmt.Sprintf("unable to write jobs to path %v: %v.", p, err))
	}
}

// generateJobs generates jobs based on the specified options.
func generateJobs(o options) {
	presets := combinePresets(o.Presets)

	if err := filepath.Walk(o.Input, func(p string, info os.FileInfo, err error) error {
		if err != nil {
			return nil
		}

		absPath, _ := filepath.Abs(p)

		if !util.HasExtension(absPath, yamlExt) {
			return nil
		}

		outPath := getOutPath(o, absPath, o.Input)
		if outPath == "" {
			return nil
		}
		if o.Clean {
			cleanOutFile(outPath)
		}

		jobs, err := config.ReadJobConfig(absPath)
		if err != nil {
			return nil
		}

		presubmit := map[string][]config.Presubmit{}
		postsubmit := map[string][]config.Postsubmit{}
		periodic := []config.Periodic{}

		// Presubmits
		for orgrepo, pre := range jobs.PresubmitsStatic {
			orgrepo = convertOrgRepoStr(o, orgrepo)
			if orgrepo == "" {
				continue
			}

			for _, job := range pre {
				valid := validateJob(o, job.Name, job.Branches, "presubmit")
				if !valid {
					continue
				}

				updateExtraRefs(o, job.ExtraRefs)
				updateJobBase(o, &job.JobBase, orgrepo)
				updateBrancher(o, &job.Brancher)
				updateUtilityConfig(o, &job.UtilityConfig)
				resolvePresets(o, job.Labels, &job.JobBase, append(presets, jobs.Presets...))

				presubmit[orgrepo] = append(presubmit[orgrepo], job)
			}
		}

		// Postsubmits
		for orgrepo, post := range jobs.Postsubmits {
			orgrepo = convertOrgRepoStr(o, orgrepo)
			if orgrepo == "" {
				continue
			}

			for _, job := range post {
				valid := validateJob(o, job.Name, job.Branches, "postsubmit")
				if !valid {
					continue
				}

				updateExtraRefs(o, job.ExtraRefs)
				updateJobBase(o, &job.JobBase, orgrepo)
				updateBrancher(o, &job.Brancher)
				updateUtilityConfig(o, &job.UtilityConfig)
				resolvePresets(o, job.Labels, &job.JobBase, append(presets, jobs.Presets...))

				postsubmit[orgrepo] = append(postsubmit[orgrepo], job)
			}
		}

		// Periodic
		for _, job := range jobs.Periodics {
			if !validateJob(o, job.Name, []string{}, "periodic") {
				continue
			}

			if len(job.ExtraRefs) == 0 {
				continue
			}

			if allRefs(job.ExtraRefs, func(val prowjob.Refs, idx int) bool {
				return !validateOrgRepo(o, val.Org, val.Repo)
			}) {
				continue
			}

			updateExtraRefs(o, job.ExtraRefs)
			updateJobBase(o, &job.JobBase, "")
			updateUtilityConfig(o, &job.UtilityConfig)
			resolvePresets(o, job.Labels, &job.JobBase, append(presets, jobs.Presets...))

			periodic = append(periodic, job)
		}

		if o.Verbose {
			fmt.Printf("write %d presubmits, %d postsubmits, and %d periodics to path %v\n", len(presubmit), len(postsubmit), len(periodic), outPath)
		}

		if !o.DryRun {
			writeOutFile(o, outPath, presubmit, postsubmit, periodic)
		}

		return nil
	}); err != nil {
		util.PrintErr(err.Error())
	}
}

// main entry point.
func Main() {
	defer handleRecover()

	var o options

	o.parseOpts()

	if err := o.validateOpts(); err != nil {
		util.PrintErrAndExit(err)
	}

	optsList := []options{o}
	optsList = append(optsList, o.parseConfiguration()...)

	for _, o := range optsList {
		generateJobs(o)
	}
}
